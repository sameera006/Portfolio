---
title: "Week 6- Classification-1"
---

## SUMMARY

Classification can be used in many studies like Urban Expansion using Landsat data, Air pollution, Urban green Spaces, monitoring forest like illegal logging, and Forest fires. in all these studies land cover is extracted from the earth observation data.

So, the process of classification involves inductive learning which means that by looking at the map we know where is ground or barren land or urban or forest area and accordingly we can classify.

For classification we use an expert system.

![](images/main-qimg-a63e873b68b7d220020991140f0a896c-lq.jpg)

[@whatis]

so the expert system consist of the knowledge base and inference engine. what we want to find out how a computer replicate human knowledge. and how expert system is applied to remote sensing.

Machine learning is defined as the science of computer modeling of learning process. there are number of machine learning data decision tree /regression tree.

**CART (Classification and Regression Tree)**

**Classification tree** classify data into two or more discrete categories. For example Landcover. Its a tree-like graph with nodes and leaves. Another example we can take is if we want to play badminton which dependens on the conditions outside hot or cold, the speed of wind and the weather.

|                                            |                                  |
|--------------------------------------------|----------------------------------|
| ![](images/decision-tree.png){width="266"} | ![](images/dt1.png){width="286"} |

[@decision]

**Regression trees** predict continuous dependant variable like numerical variable for example total PopulationThey subset the data into smaller chunks. When we create decision tree the end leaves might be a mixture of categories meaning they are impure known as Gini impurity. the option with the lowest impurity goes to the top of the tree and becomes the root.

While discussing model prediction it is important to understand prediction errors(bias and variance). so it is very important to understand these errors which will help us build accurate models and avoid the mistake of **overfitting** and **underfitting**. [@singh2018]

So decision trees are not good with new or big size data. Higher depth DTs are more prone to overfitting and thus leads to higher variance. This shortcoming of DTs is explored by random forest model.

**Random Forests**

Random Forests (RFs) are composed of multiple independent decision trees that are trained independently on a random subset of data.

![](images/1_ixvrbH45K8CcNZaj98JGuA.webp)

[@bhatia2019]

In RFs we talk about bootstrapping and out of bag(OOB) error which is basically we do not train all the values and what is left is then tested and validated with the model. the left out varibles are called OOB.

how do we apply these methods with the satellite imagery?

**Image Classification Techniques** - it is the process of assigning landcover classes to pixels. For example classes include water, urban, Forest, agriculture and grassland.

1.  Supervised

2.  Unsupervised

3.  Object based Image Classification

    Unsupervised classification usually referred as clustering/k-means. some common clustering algorithm are ISODATA.

    Supervised Classification we use Maximum likelihood and support vector machines(SVM).

## APPLICATION

[@tariq2023]

[@hansen2013]

[@shahtahmassebi2021]

## REFLECTION

So, this week was about classification and had a lot of content to cover. I think this is the most important lecture because all the methods taught during the lecture are used very commonly for digital image processing and in future will be used mostly. I understood about decision trees and random forest and how machine learning plays an important role in the field of remote sensing. By week 6 all we did earlier is making sense and helpful in understanding about different applications where we can use this like detecting fires, flood risk, desertification and LULC heat maps.
